{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!git clone https://github.com/akTwelve/Mask_RCNN\n",
    "%cd Mask_RCNN/\n",
    "!pip install -r requirements.txt\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!wget https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5\n",
    "##%%\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import skimage.draw\n",
    "import tensorflow as tf\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib, utils\n",
    "\n",
    "# Path to trained weights file\n",
    "COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "\n",
    "# Directory to save logs and model checkpoints, if not provided\n",
    "# through the command line argument --logs\n",
    "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class BalloonConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy  dataset.\n",
    "    Derives from the base Config class and overrides some values.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"balloon\"\n",
    "\n",
    "    # We use a GPU with 12GB memory, which can fit two images.\n",
    "    # Adjust down if you use a smaller GPU.\n",
    "    IMAGES_PER_GPU = 2\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 80 + 1  # Background + balloon\n",
    "\n",
    "    # Number of training steps per epoch\n",
    "    STEPS_PER_EPOCH = 100\n",
    "\n",
    "    # Skip detections with < 90% confidence\n",
    "    DETECTION_MIN_CONFIDENCE = 0.2\n",
    "\n",
    "    CLASS_DICT = {0: u'__background__',\n",
    "                  1: u'person',\n",
    "                  2: u'bicycle',\n",
    "                  3: u'car',\n",
    "                  4: u'motorcycle',\n",
    "                  5: u'airplane',\n",
    "                  6: u'bus',\n",
    "                  7: u'train',\n",
    "                  8: u'truck',\n",
    "                  9: u'boat',\n",
    "                  10: u'traffic light',\n",
    "                  11: u'fire hydrant',\n",
    "                  12: u'stop sign',\n",
    "                  13: u'parking meter',\n",
    "                  14: u'bench',\n",
    "                  15: u'bird',\n",
    "                  16: u'cat',\n",
    "                  17: u'dog',\n",
    "                  18: u'horse',\n",
    "                  19: u'sheep',\n",
    "                  20: u'cow',\n",
    "                  21: u'elephant',\n",
    "                  22: u'bear',\n",
    "                  23: u'zebra',\n",
    "                  24: u'giraffe',\n",
    "                  25: u'backpack',\n",
    "                  26: u'umbrella',\n",
    "                  27: u'handbag',\n",
    "                  28: u'tie',\n",
    "                  29: u'suitcase',\n",
    "                  30: u'frisbee',\n",
    "                  31: u'skis',\n",
    "                  32: u'snowboard',\n",
    "                  33: u'sports ball',\n",
    "                  34: u'kite',\n",
    "                  35: u'baseball bat',\n",
    "                  36: u'baseball glove',\n",
    "                  37: u'skateboard',\n",
    "                  38: u'surfboard',\n",
    "                  39: u'tennis racket',\n",
    "                  40: u'bottle',\n",
    "                  41: u'wine glass',\n",
    "                  42: u'cup',\n",
    "                  43: u'fork',\n",
    "                  44: u'knife',\n",
    "                  45: u'spoon',\n",
    "                  46: u'bowl',\n",
    "                  47: u'banana',\n",
    "                  48: u'apple',\n",
    "                  49: u'sandwich',\n",
    "                  50: u'orange',\n",
    "                  51: u'broccoli',\n",
    "                  52: u'carrot',\n",
    "                  53: u'hot dog',\n",
    "                  54: u'pizza',\n",
    "                  55: u'donut',\n",
    "                  56: u'cake',\n",
    "                  57: u'chair',\n",
    "                  58: u'couch',\n",
    "                  59: u'potted plant',\n",
    "                  60: u'bed',\n",
    "                  61: u'dining table',\n",
    "                  62: u'toilet',\n",
    "                  63: u'tv',\n",
    "                  64: u'laptop',\n",
    "                  65: u'mouse',\n",
    "                  66: u'remote',\n",
    "                  67: u'keyboard',\n",
    "                  68: u'cell phone',\n",
    "                  69: u'microwave',\n",
    "                  70: u'oven',\n",
    "                  71: u'toaster',\n",
    "                  72: u'sink',\n",
    "                  73: u'refrigerator',\n",
    "                  74: u'book',\n",
    "                  75: u'clock',\n",
    "                  76: u'vase',\n",
    "                  77: u'scissors',\n",
    "                  78: u'teddy bear',\n",
    "                  79: u'hair drier',\n",
    "                  80: u'toothbrush'}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def color_splash(image, mask):\n",
    "    \"\"\"Apply color splash effect.\n",
    "    image: RGB image [height, width, 3]\n",
    "    mask: instance segmentation mask [height, width, instance count]\n",
    "    Returns result image.\n",
    "    \"\"\"\n",
    "    # Make a grayscale copy of the image. The grayscale copy still\n",
    "    # has 3 RGB channels, though.\n",
    "    gray = skimage.color.gray2rgb(skimage.color.rgb2gray(image)) * 255\n",
    "    # Copy color pixels from the original color image where mask is set\n",
    "    if mask.shape[-1] > 0:\n",
    "        # We're treating all instances as one, so collapse the mask into one layer\n",
    "        mask = (np.sum(mask, -1, keepdims=True) >= 1)\n",
    "        splash = np.where(mask, image, gray).astype(np.uint8)\n",
    "    else:\n",
    "        splash = gray.astype(np.uint8)\n",
    "    return splash"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def detect_and_color_splash(model, image_path=None, video_path=None, outpath=None):\n",
    "    assert image_path or video_path\n",
    "\n",
    "    # Image or video?\n",
    "    if image_path:\n",
    "        # Run model detection and generate the color splash effect\n",
    "        print(\"Running on {}\".format(args.image))\n",
    "        # Read image\n",
    "        image = skimage.io.imread(args.image)\n",
    "        # Detect objects\n",
    "        r = model.detect([image], verbose=1)[0]\n",
    "        # Color splash\n",
    "        splash = color_splash(image, r['masks'])\n",
    "        # Save output\n",
    "        file_name = \"splash_{:%Y%m%dT%H%M%S}.png\".format(datetime.datetime.now())\n",
    "        file_name = outpath\n",
    "        skimage.io.imsave(file_name, splash)\n",
    "    elif video_path:\n",
    "        import cv2\n",
    "        # Video capture\n",
    "        vcapture = cv2.VideoCapture(video_path)\n",
    "        width = int(vcapture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(vcapture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = vcapture.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "        # Define codec and create video writer\n",
    "        file_name = \"splash_{:%Y%m%dT%H%M%S}.avi\".format(datetime.datetime.now())\n",
    "        vwriter = cv2.VideoWriter(file_name,\n",
    "                                  cv2.VideoWriter_fourcc(*'MJPG'),\n",
    "                                  fps, (width, height))\n",
    "\n",
    "        count = 0\n",
    "        success = True\n",
    "        while success:\n",
    "            print(\"frame: \", count)\n",
    "            # Read next image\n",
    "            success, image = vcapture.read()\n",
    "            if success:\n",
    "                # OpenCV returns images as BGR, convert to RGB\n",
    "                image = image[..., ::-1]\n",
    "                # Detect objects\n",
    "                r = model.detect([image], verbose=0)[0]\n",
    "                # Color splash\n",
    "                splash = color_splash(image, r['masks'])\n",
    "\n",
    "                # Draw Bboxes\n",
    "                for count, box in enumerate(r['rois']):\n",
    "                    # Shape (y1, x1, y2, x2, class_id)\n",
    "                    splash = cv2.rectangle(splash, (box[1], box[0]), (box[3], box[2]), (255, 0, 0), 2)\n",
    "                    class_id = r['class_ids'][count]\n",
    "                    splash = cv2.putText(splash, config.CLASS_DICT[class_id], (box[3], box[2]), cv2.FONT_HERSHEY_COMPLEX,\n",
    "                                         2, (255,0,0), 2)\n",
    "\n",
    "                # RGB -> BGR to save image to video\n",
    "                splash = splash[..., ::-1]\n",
    "                # Add image to video writer\n",
    "                vwriter.write(splash)\n",
    "                count += 1\n",
    "        vwriter.release()\n",
    "    print(\"Saved to \", file_name)\n",
    "\n",
    "\n",
    "command = 'splash'\n",
    "weights = 'coco'\n",
    "dataset = ''\n",
    "logs = ''\n",
    "image = None\n",
    "video = ''\n",
    "output = ''\n",
    "print_model = True\n",
    "viz_feat_map = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Validate arguments\n",
    "if command == \"train\":\n",
    "    assert dataset, \"Argument --dataset is required for training\"\n",
    "elif command == \"splash\":\n",
    "    pass\n",
    "print(\"Weights: \", weights)\n",
    "print(\"Dataset: \", dataset)\n",
    "print(\"Logs: \", logs)\n",
    "# Configurations\n",
    "if command == \"train\":\n",
    "    config = BalloonConfig()\n",
    "else:\n",
    "    class InferenceConfig(BalloonConfig):\n",
    "        # Set batch size to 1 since we'll be running inference on\n",
    "        # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "        GPU_COUNT = 1\n",
    "        IMAGES_PER_GPU = 1\n",
    "    config = InferenceConfig()\n",
    "config.display()\n",
    "# Create model\n",
    "if command == \"train\":\n",
    "    model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                              model_dir=logs)\n",
    "else:\n",
    "    model = modellib.MaskRCNN(mode=\"inference\", config=config,\n",
    "                              model_dir=logs)\n",
    "# Select weights file to load\n",
    "if weights.lower() == \"coco\":\n",
    "    weights_path = COCO_WEIGHTS_PATH\n",
    "    # Download weights file\n",
    "    if not os.path.exists(weights_path):\n",
    "        utils.download_trained_weights(weights_path)\n",
    "elif weights.lower() == \"last\":\n",
    "    # Find last trained weights\n",
    "    weights_path = model.find_last()\n",
    "elif weights.lower() == \"imagenet\":\n",
    "    # Start from ImageNet trained weights\n",
    "    weights_path = model.get_imagenet_weights()\n",
    "else:\n",
    "    weights_path = weights\n",
    "# Load weights\n",
    "print(\"Loading weights \", weights_path)\n",
    "if weights.lower() == \"coco\":\n",
    "    # Exclude the last layers because they require a matching\n",
    "    # number of classes\n",
    "    #model.load_weights(weights_path, by_name=True, exclude=[\n",
    "    #    \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
    "    #    \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "    model.load_weights(weights_path, by_name=True)\n",
    "else:\n",
    "    model.load_weights(weights_path, by_name=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if print_model:\n",
    "    model.keras_model.summary()\n",
    "    for i in range(len(model.layers)):\n",
    "        layer = model.layers[i]\n",
    "        #if 'conv' not in layer.name:\n",
    "        #    continue\n",
    "        print(i, layer.name, layer.output_shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if viz_feat_map:\n",
    "    feat_model = tf.keras.Model(inputs=model.input, outputs=model.layers)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train or evaluate\n",
    "if command == \"splash\":\n",
    "    detect_and_color_splash(model, image_path=image,\n",
    "                            video_path=video, outpath=output)\n",
    "else:\n",
    "    print(\"'{}' is not recognized. \"\n",
    "          \"Use 'train' or 'splash'\".format(command))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from google.colab import auth\n",
    "from googleapiclient.http import MediaFileUpload\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "auth.authenticate_user()\n",
    "drive_service = build('drive', 'v3')\n",
    "\n",
    "def save_file_to_drive(name, path):\n",
    "  file_metadata = {'name': name, 'mimeType': 'application/octet-stream'}\n",
    "  media = MediaFileUpload(path, mimetype='application/octet-stream', resumable=True)\n",
    "  created = drive_service.files().create(body=file_metadata, media_body=media, fields='id').execute()\n",
    "\n",
    "  return created\n",
    "\n",
    "save_file_to_drive('output.avi', output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}